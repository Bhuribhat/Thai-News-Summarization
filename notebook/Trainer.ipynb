{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88feb5e8-81c7-41e8-88be-dfb57bdb3141",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79523d5a-1a5f-4c1d-93bd-c8a81379f379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 14 13:05:51 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:04:00.0 Off |                  N/A |\n",
      "| 53%   43C    P8             39W /  390W |      10MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off |   00000000:05:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8             46W /  390W |      10MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1169      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A      1169      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992e26b-8bfa-43b1-80ad-d5b2abd32869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import get_scheduler\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "from transformers import Trainer\n",
    "from transformers import TrainerCallback\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from datasets import load_dataset, Dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c549fab1-c569-4daf-b2a4-d012fdbae3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 2 cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"using {n_gpu} {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e9654-a103-46f4-afb7-29ad54643b94",
   "metadata": {},
   "source": [
    "# Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f8b78-8f15-4244-a917-a2a445052d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de37b2c-a6e3-4c62-aa35-ec7f8af2e660",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "Encoder - Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deeaf6c0-6155-4bcd-a513-3063d06ff759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, torch_dtype=torch.bfloat16)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e9b9c-cac0-45ad-ac27-a4085f15eea5",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88a639a-c5a8-4abe-b153-55adeb6e5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = load_from_disk('preprocessed_thaisum.hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbea3f-cd65-4220-a862-f71994356fd5",
   "metadata": {},
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb56ac4-93d2-4340-aca2-e71de7b7e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def deep_tokenize(word):\n",
    "    return word_tokenize(word, engine=\"deepcut\")\n",
    "\n",
    "\n",
    "def compute_metrics(predictions , labels):\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    print(\"label =\", decoded_labels[0])\n",
    "    print(\"predict =\", decoded_preds[0])\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True , tokenizer=deep_tokenize)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d642b0-25ac-4043-9948-68967f03de1a",
   "metadata": {},
   "source": [
    "# Data Collector & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1735d5-c2bd-4c1d-86b0-6b39d1237294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13749c67-bd14-4bcf-935c-84f1a148f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, num_steps=10):\n",
    "        self.num_steps = num_steps\n",
    "    \n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step >= self.num_steps:\n",
    "            return {\"should_training_stop\": True}\n",
    "        else:\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f04b59-b276-4e80-8265-b46c2166d9ac",
   "metadata": {},
   "source": [
    "# Fine-tune a pretrained model\n",
    "\n",
    "- https://huggingface.co/docs/transformers/en/training\n",
    "- https://huggingface.co/docs/transformers/main/en/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b47e8a-2805-47a0-a1c2-4a7d3b62a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    # load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8a717-080f-4b75-b584-eb4adcd73230",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a374a09a-c785-4fa9-8207-b17ad00de280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE using only 1 gpu instead of 2\n",
    "limit_n_gpu_to_1 = False\n",
    "if limit_n_gpu_to_1:\n",
    "    trainer.args._n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0db119-9a46-4b62-b690-da5bce55dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume from latest checkpoint\n",
    "resume_from_checkpoint = False\n",
    "trainer.train(resume_from_checkpoint=resume_from_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c953e24-5b9a-46b8-a222-16dbadb89406",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4d40f-9d08-4fbb-9b9b-1dcc0a0ad03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
